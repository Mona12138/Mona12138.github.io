<!DOCTYPE html><html lang="chinese" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Mona - hello</title><meta name="author" content="Mona"><meta name="copyright" content="Mona"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><!-- add chat model--><!--meta(name="keywords" content=page.keywords || auto_keyword_desc(page.content).keywords || config.keywords)--><!--meta(name="description" content=page.description || auto_keyword_desc(page.content).description || config.description)--><meta property="og:type" content="website">
<meta property="og:title" content="Mona">
<meta property="og:url" content="https://mona12138.github.io/page/3/index.html">
<meta property="og:site_name" content="Mona">
<meta property="og:locale">
<meta property="og:image" content="https://mona12138.github.io/img/nav.png">
<meta property="article:author" content="Mona">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mona12138.github.io/img/nav.png"><link rel="shortcut icon" href="/img/nav.png"><link rel="canonical" href="https://mona12138.github.io/page/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"You have switched to Traditional Chinese","cht_to_chs":"You have switched to Simplified Chinese","day_to_night":"You have switched to Dark Mode","night_to_day":"You have switched to Light Mode","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Mona',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2025-04-28 15:36:06'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><!--chatai--><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (true) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/nav.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('/img/nav.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Mona"><img class="site-icon" src="/nav.png"/><span class="site-name">Mona</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Mona</h1><div id="site-subtitle"><span id="subtitle"></span></div><div id="site_social_icons"><a class="social-icon" href="https://github.com/mona12138" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://github.com/mona12138" target="_blank" title="Github"><i class="fab fa-gitHub" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:manyuwei@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/10/27/%E8%8B%B1%E8%AF%AD/%E6%97%A9%E5%AE%89%E8%8B%B1%E6%96%87/%E9%BB%84%E9%87%91%E4%BB%B7%E6%A0%BC%E4%B8%BA%E4%BD%95%E4%B8%80%E8%B7%AF%E6%94%80%E5%8D%87%EF%BC%9F%E6%84%8F%E5%91%B3%E7%9D%80%E4%BB%80%E4%B9%88%EF%BC%9F/" title="黄金价格为何一路攀升？意味着什么？">黄金价格为何一路攀升？意味着什么？</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-10-27T00:42:45.974Z" title="Created 2024-10-27 08:42:45">2024-10-27</time></span></div><div class="content">标题:What the surging(极度飙升) gold price says about a dangerous
world Financial fears and geopolitical（地缘政治）
tremors（动荡；小地震） combine to great effect
正文： Less than a mile from Singapore’s
luxurious（奢华的;luxury奢华） Changi(樟宜机场) Airport sits a rather
less glamorous（豪华；光鲜亮丽） business park（工业园区）.
Residents（居民） of the industrial estate（财产） include
freight（货运） and logistics
firms（物流公司，logistics 货运）, as well as the back
offices（后勤部门） of several banks. One building is a little
different,however. Behind a glossy（光亮的，闪眼睛） onyx（玛瑙）
facade（大型建筑物的正面，虚假的外表）, layers of security（安保） and
imposing(雄伟) steel doors（钢门）, sits more than $1bn
in gold, silver(银子) and other treasures（珍宝）. “The Reserve”
hosts（主持，这里指拥有） dozens of private vaults（保险库）, thousands
of and a cavernous（cave-洞穴-&gt;cavernous 如同洞穴一般的，深凹，深陷）
storage room where precious metals sit on shelves（货架） rising three
storeys above the ground. 知识点：luxurious adj. /lʌɡˈʒʊəriəs/ very
comfortable; containing expensive and enjoyable things⼗分舒适的；奢侈的
• a luxurious hotel豪华宾馆 • luxurious surroundings豪华舒适的环境
正文： Less than a mile from Singapore’s luxurious Changi Airport
sits a rather less glamorous business park. Residents of the industrial
estate include freight and logistics firms, as well as the back offices
of several banks. One building is a little different, however. Behind a
glossy onyx facade, layers of security and imposing steel doors, sits
more than $1bn in gold, silver and other treasures. “The Reserve” hosts
dozens of private vaults, thousands of and a cavernous storage room
where precious metals sit on shelves rising three storeys above the
ground. 翻译：
距离新加坡豪华的樟宜机场不到一英里，坐落着一个不太迷人的商业园区。工业区居民包括货运
和物流公司，以及几家银行的后台。然而，一栋建筑略有不同。在光滑的缟玛瑙外观、层层安全措施和雄伟的钢门后面，藏着价值超过
10 亿美元的黄金、白银和其他珍宝。
“保护区”拥有数十个、数千个私人金库和一个巨大的储藏室，贵金属存放在离地面三层楼高的架子上。
</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/10/24/%E8%8B%B1%E8%AF%AD/%E6%97%A9%E5%AE%89%E8%8B%B1%E6%96%87/%E7%A1%85%E8%B0%B7%E5%A4%A7%E4%BD%AC%E4%BB%AC%E4%B8%BA%E4%BD%95%E5%A6%82%E6%AD%A4%E7%83%AD%E8%A1%B7%E4%BA%8E%E6%8D%90%E7%B2%BE%EF%BC%9F/" title="The sperm donor bros of tech">The sperm donor bros of tech</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-10-24T08:36:53.136Z" title="Created 2024-10-24 16:36:53">2024-10-24</time></span></div><div class="content">标题:The
sperm（精子） donor(捐赠者) bros(男的) of tech（科技领域）
科技领域的捐精男
Genetic（基因上的） largesse（施舍，慷慨的） from some of Silicon
Valley's elite（精英） appears to be a mix of narcissism（自恋）,
altruism（利他主义） and dreams of immortality（不朽） 正文: Before he
was arrested in France for failing to adequately moderate
（考核，审查）criminal activity on his social media app, tech
billionaire（亿万富翁） PavelDurov was known for three things:
founding（创立） Telegram, posting thirst-trap photos（性感照片） on
Instagram and fathering（给..当爸爸） over 100 children.
知识点: adequate adj./ædikwat/ enough in quantity, or good enough in
quality, for a particular purposeor need足够的;合格的;合乎需要的 - an
adequate supply of hot water热水供应充足 - The room was small but
adequate.房间虽小但够用
原文： Genetic largesse from some of Silicon Valley's elite appears
to be a mix of narcissism, altruism and dreams ofimmortality 正文:
Before he was arrested in France for failing to adequately moderate
criminal activity on his social media app, tech billionaire PavelDurov
was known for three things: founding Telegram, posting thirst-trap
photos on Instagram and fathering over 100 children.
The last fact is a relatively recent revelation. This summer, Durov
surprised his online followers by revealing that a sperm donation he
made to a fertility clinic had resulted in children conceived in 12
countries by more than 100couples.
</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/10/24/%E8%8B%B1%E8%AF%AD/%E6%97%A9%E5%AE%89%E8%8B%B1%E6%96%87/%E5%93%88%E9%A9%AC%E6%96%AF%E6%9C%80%E9%AB%98%E9%A2%86%E5%AF%BC%E4%BA%BA%E8%BE%9B%E7%93%A6%E5%B0%94%E8%A2%AB%E5%87%BB%E6%AF%99/" title="Final video of Hamas leader Yahya">Final video of Hamas leader Yahya</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-10-24T01:01:48.632Z" title="Created 2024-10-24 09:01:48">2024-10-24</time></span></div><div class="content">Sinwar transfixes Gaza Drone footage of chief’s demise has reshaped
views among some Palestinians exhausted by war
For months, Israel has portrayed the Hamas leader Yahya Sinwar as
holed up in the militant group’s fortified tunnel network under Gaza,
shielding himself from Israeli bombs. But when many Palestinians in the
strip watched the Israeli drone footage of Sinwar’s killing, they saw
the Hamas chief above ground, dressed in military fatigues and with one
arm partially severed, using his remaining hand to attack the drone with
the only weapon he had — a stick.
精讲笔记： Final video of Hamas leader Yahya
Sinwar(人名，Hamas的最高领导人) transfixes(惊心动魄的) Gaza
Drone(无人机) footage(影片中连续的镜头) of chief(首领)’s demise(死亡
business demise项目夭折) has reshaped views among some Palestinians
exhausted(疲惫不堪) by war
For months, Israel(以色列) has portrayed(呈现) the
Hamas leader Yahya Sinwar as (portrayed sb as
把..呈现为..)holed up(躲在hide in sp) in the militant
group’s fortified(加强的) tunnel(地道) network under Gaza,
shielding(抵挡；盾牌，此处为动词表示) himself from Israeli bombs. But
when many Palestinians(巴勒斯坦人) in the
strip(条状地带的地方（指加沙）；条状的，带状的) watched the Israeli
drone footage of Sinwar’s killing, they saw the Hamas chief above
ground, dressed in military(军用的)
fatigues(宽松一点的服装；疲劳)(military fatigues这里指军装) and with one
arm partially(部分的) severed(sever 断掉；severe 严重的), using his
remaining(剩余的) hand to attack the drone with the only weapon he had —
a stick.
原文： For months, Israel has portrayed the Hamas leader Yahya Sinwar
as holed up in the militant group’s fortified tunnel network under Gaza,
shielding himself from Israeli bombs.
But when many Palestinians in the strip watched the Israeli drone
footage of Sinwar’s killing, they saw the Hamas chief above ground,
dressed in military fatigues and with one arm partially severed, using
his remaining hand to attack the drone with the only weapon he had — a
stick.
“Even people who were angry about Hamas, when they saw...he had been
killed during clashes and not hiding in a tunnel, as Israel was always
claiming, they felt sorry and sad for him,” said Mohammed Sobeh,
speaking from Khan Younis in Gaza.
“Sinwar’s death will raise his popularity.”
Many Gazans blame Hamas’s leader for inciting Israel’s wrath with the
October 7 attack last year that killed 1,200 people in Israel, according
to Israeli officials, and triggered the devastating Gaza war. They say
Sinwar provoked Israel into unleashing the greatest catastrophe on
Palestinians since 1948.
Israel’s assault has killed about 42,500 people in Gaza, according to
health authorities in the shattered strip, which is now stalked by the
threat of famine and disease.
But the footage of Sinwar’s final moments on Thursday looked to many
in Gaza like a defiant last stand against Israel, eclipsing some of the
criticism he faced from Palestinians.
Since Sinwar’s killing, “what I’ve heard and seen is that, again,
most of the Palestinians in Gaza have a lot of respect for him”, said
Mkhaimar Abusada, associate professor of political science at Gaza’s
Al-Azhar University, now a visiting scholar at Northwestern University
in Illinois, US.
“They think he just died fighting in the frontline of the battle
against Israel, like many other Hamas fighters,” he said. “Criticism of
Sinwar just disappeared completely today.”
Arabic social media has been filled with praise from Hamas supporters
for the ruthless militant leader. “Sinwar was martyred on the ground of
Rafah in the heart of the battle,” Youssef Issa Abu Medhat said. “He was
not pulled from the tunnels. He was not arrested in his underwear.”
Abbas Araghchi, foreign minister of Iran, which supports Hamas, said
on X that Sinwar “bravely fought to the very end on the battlefield”.
“His fate — beautifully pictured in his last image — is not a deterrent
but a source of inspiration for resistance fighters across the region,”
he wrote, adding a still image of Sinwar from the drone video.
The reaction in Israel to the dramatic news of Sinwar’s death, which
included the grainy drone ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/10/14/re-id/%E4%BD%BF%E7%94%A8%E4%BA%8C%E9%98%B6transformer%E8%BF%9B%E8%A1%8C%E7%BE%A4%E4%BD%93%E9%87%8D%E6%96%B0%E8%AF%86%E5%88%AB%E7%9A%84%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%BB%BA%E6%A8%A1/" title="Uncertainty modeling with second-order transformer for group re-identification">Uncertainty modeling with second-order transformer for group re-identification</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-10-14T08:39:06.585Z" title="Created 2024-10-14 16:39:06">2024-10-14</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Uncertainty/">Uncertainty</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Group-re-id/">Group re-id</a></span></div><div class="content">出处：AAAI-2022

总结
主要解决群体行人重识别问题，采用二阶transformer的方法。先得出一个人的特征，输入到第二层，
## 摘要
群体重新识别（G-ReID）专注于关联不同摄像机下包含相同人员的群体图像。
G-ReID的关键挑战是组内成员和布局变化的所有情况都难以穷尽。
为此，我们提出了一种新颖的不确定性模型，它将每个图像视为取决于当前成员和布局的分布，然后通过随机采样挖掘潜在的群体特征。
基于潜在的和原始的群体特征，不确定性建模可以学习更好的决策边界，这是由成员变化模块（MVM）和布局变化模块（LVM）实现的。
此外，我们提出了一种新颖的二阶变压器框架（SOT），其灵感来自于变压器中的位置建模处理
GReID 任务的事实。 SOT由成员内模块和成员间模块组成。
具体来说，成员内模块提取每个成员的一阶token，然后成员间模块通过上述一阶token学习到一个二阶token作为群体特征，可以将其视为token。
在三个可用数据集（包括 CSG、DukeGroup 和
RoadGroup）上进行了大量实验，结果表明所提出的 SOT
优于之前所有最先进的方法。 ## 引言
群体重新识别（G-ReID）旨在根据相似性将不同摄像机下包含相同成员的群体图像与不重叠的视图关联起来。
G-ReID通常关注2~6个成员的群体，属于同一群体类别的图像应包含至少60%的相同成员。
G-ReID是比行人重新识别更关键和更具挑战性的任务，因为人们通常具有群体和社交属性，这表明人们在大多数真实场景中更喜欢群体移动。
因此，G-ReID需要处理成员和布局变化。具体来说，成员变化是指由于成员离开或服务遮挡而导致组内成员数量减少，布局变化是指在不同摄像机下空间位置可能发生变化。

尽管有一些基于深度学习的开创性工作（Huang et al. 2021；Lin et al.
2021；Zhu et al. 2020；Yan et al.
2020）来解决上述挑战，但表现并不令人满意。 其缺点主要有以下两个原因。
1）现有作品提取的特征是固定成员和布局下群体图像的具体特征。如图1所示，从橙色三角形和绿色方块学习到的类边界是整个类的局部表示，这导致基于局部边界的决策边界（红色虚线）不能很好地区分两堂课。
2）现有模型基于CNN和GNN的组合框架，由于结构本身在位置建模方面的缺陷，对组布局特征的描述能力较弱，因此性能受到限制。
在本文中，我们提出了一种新颖的不确定性模型，其动机是每个组中包含的成员和布局的变化是无限多样的。
无论从现实世界中如何精心采样，所有情况都无法穷尽。
因此，不确定性是群体形象的固有属性，无法通过大规模数据的收集而消失。
所提出的不确定性模型将每个群体图像视为一个分布而不是特定样本，然后通过对分布进行动态采样，挖掘出当前群体在其他可能成员和布局下的几个潜在群体特征。
成员变化模块（MVM）和布局变化模块（LVM）这两个模块被设计来构建每个图像的特定概率分布。
如图1所示，通过不确定性建模学习到的群体特征（三角形和正方形）更接近真实边界，并且与现实世界的分布一致。
训练和优化这个真实边界可以获得更多可分离的决策边界和更鲁棒的特征表示。
具体来说，所提出的 MVM 定义了一个随机变量 p
来描述组内成员变异的概率分布。 标准形式 p
的构造具有以下属性。首先，群体成员在跨多个镜头出现时往往会保持稳定。
其次，当变异偶尔发生时，变异概率会随着消失成员的增加而降低。
考虑到输入并不总是包含其组类的所有成员，我们将动态约束标准 p
以适合每个图像
LVM 关注每个成员的布局变化。由于很难穷举所有的空间位置，LVM
将一定数量的成员下所有可能的空间位置归一化为同一个布局特征。
为此，设计了可学习的存储体M来描述布局特征。对于有 j 个成员的组，采用 M
的第 j 列作为每个成员的标准化布局特征。
LVM的优点是归一化布局可以避免连续位置分布上的过采样。
此外，受 Transformer 中位置嵌入的启发，我们提出了二阶 Transformer
模型（SOT），该模型可应对 G-ReID 中的布局特征。 传统的 CNN-GNN
模型缺乏空间位置建模，导致性能较低，我们的模型可以克服这一问题。 拟议的
SOT
由成员内部和成员间模块组成。对于一个组图像，SOT首先裁剪每个成员，然后将每个成员分割成多个patch。
成员内模块通过成员特征转换器对子patch之间的关系进行建模，提取一阶标记作为每个成员特征。
然后成员间模块通过不确定性建模对成员之间的群体关系进行建模，并通过群体特征转换器提取二阶token作为群体特征，群体特征转换器接收一阶token并输出token。
贡献： -
我们提出了不确定性建模，它将每个图像视为一个分布而不是特定的样本。不确定性建模旨在通过对分布进行随机采样来探索潜在的群体变化，这是通过提出的成员变化模块（MVM）和布局变化模块（LVM）来实现的
-
我们提出了二阶变换器（SOT），提取令牌作为成员特征，提取令牌的令牌作为组特征。
SOT可以有效地提取布局特征，这在现有方法中是困难的。 - SOT 在
CSG、DukeGroup 和 RoadGroup 数据集上实现了 91.7%/90.7%、72.7%/78.9% 和
86.4%/91.3% 的 Rank-1/mAP，比最先进的方法高出 28.5%、15.3 %，排名 1 的为
1.9%。
相关工作
人员重新识别。行人重新识别（ReID）旨在将摄像头网络中的单个行人与不重叠的视图关联起来。
最近，许多方法（Sun et al. 2018；Wang et al. 2018；Dai et al. 2021；He
et al. 2021b；Bai et al. 2021；Zhao et al. 2021；Wu、Zhu和Gong
2022）基于深度学习在这一领域取得了重大进展，包括提取更多的判别性特征和设计更合适的指标。
例如，OSNet (Zhou et al. 2019) 和 OSNet-AIN (Zhou et al. 2021)
设计了一种新颖的主干网，既考虑了判别性特征学习又考虑了计算成本。 AGW（Ye
et al. 2021）提出了一种加权正则化三元组度量学习方法。
然而，上述工作并不适合G-ReID，因为这些工作只关注个体行人的外观特征，而忽略了群体内成员之间的关系。
所提出的SOT克服了现有工作的缺点，并明确地建模了成员的数量和布局关系，从而大大提高了性能。
群体重新识别。与 ReID 相比，G-ReID
研究较少，只有少数开创性工作尝试解决此任务。
一些早期的工作（Zheng，Gong和Xiang 2009；Cai，Takala和Pietik ̈ ainen
2010；Zhu，Chu和Yu 2016；Lisanti等人2017）
将整个图像作为模型的输入，并直接提取群体特征。由于这些作品都是基于手工制作的特征，并且考虑了背景信息，因此表现并不理想。
最近，基于CNN的工作（Mei et al.
2020、2019、2021）已成为主流研究，其裁剪组内成员，然后提取组特征。
例如，DotGNN（Huang et al. 2019）采用CycleGAN（Zhu et al.
2017）来获得风格迁移，然后将成员特征与GNN集成以提取群体特征。 MRF（Xiao
et al. 2018；Lin et al.
2021）考虑了更细粒度的隶属度，并提出了一种多阶匹配方法来计算相似度。
GCGNN (Zhu et al. 2020) 使用 K
最近成员对每个成员进行编码，然后设计群体上下文 GNN 来提取群体特征。
MACG（Yan et al.
2020）提出了一种多注意力上下文图框架，将复杂的注意力机制应用于群体特征学习。
上述工作的性能并不理想，主要是因为：1）它们基于CNN和GNN框架，对组布局建模能力较弱；
2）它们属于确定性建模。所提出的 SOT 可以克服这些缺点。
变压器。 Transformer（Vaswani et al. 2017）被提出来提取 NLP
任务中的文本特征，然后推广到许多 CV 任务并取得了良好的性能。
例如，IPT（Chen et al.
2021）采用大规模预训练变压器，在许多低级视觉任务上取得了良好的性能。 ViT
(Dosovitskiy et al. 2021) 是一个纯粹的转换器，它直接将图像分成几个块。
SwinTransformer (Liu et al. 2021) 在目标检测方面取得了令人满意的性能。
DETR（Carion
等人，2020）提出了一种端到端框架，将编码器和解码器结合在一起进行对象检测。
TransReID（He et al. 2021a）首先将变压器引入行人重新识别中。
然而，Transformer在G-ReID中并没有受到太多关注。为此，我们提出了二阶变压器来处理
G-ReID。
方法
在本节中，我们首先介绍不确定性建模的 MVM 和 LVM，然后描述所提出的 SOT
网络。图2详细说明了该方法。 ### 成员变量模块 (MVM)
本文中，MVM旨在为每幅图像构建特定的概率分布，并通过随机采样来确定组内成员的存在。
因此，关键问题是如何获得概率分布的具体形式。我们约束概率分布以满足以下两个属性，以便它可以模拟现实场景中的变化。
• 稳定性：对于一个稳健的群体，群体内成员的数量通常保持不变。 •
随机性：当鲁棒群体偶尔发生变化时，Zd 成员发生变化的概率会随着Zd
的增加而显着降低。形式上，概率分布可以描述 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/09/15/re-id/VI-ReID/PartMix/" title="PartMix：学习可见红外人员重新识别零件发现的正则化策略"><img class="post-bg" src="/2024/09/15/re-id/VI-ReID/PartMix/img_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PartMix：学习可见红外人员重新识别零件发现的正则化策略"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/15/re-id/VI-ReID/PartMix/" title="PartMix：学习可见红外人员重新识别零件发现的正则化策略">PartMix：学习可见红外人员重新识别零件发现的正则化策略</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-09-15T07:40:31.987Z" title="Created 2024-09-15 15:40:31">2024-09-15</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/VI-ReID/">VI-ReID</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/%E5%88%86%E5%9D%97/">分块</a></span></div><div class="content">PartMix:
Regularization Strategy to Learn Part Discovery for Visible-Infrared
Person Re-identification
CVPR2023 ## Summery
写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段 ##
研究目标 VI-ReID、 一种数据增强技术 ## Problem Statement 
使用基于混合的技术的现代数据增强可以规范模型，
避免对各种计算机视觉应用中的训练数据过度拟合，
但针对基于部件的可见红外人员重新识别（VI-ReID）模型量身定制的适当数据增强技术仍未被探索。
VIReID 数据增强方法的比较。 - 使用全局图像混合的 MixUp [69] -
使用局部图像混合的 CutMix [68] 可用于正则化 VI-ReID
模型，但这些方法提供的性能有限，因为它们会产生不自然的模式或局部模式。仅具有背景或单个人体部分的补丁。
- PartMix 使用零件描述符混合策略，这提高了 VI-ReID
性能（最佳颜色查看）。
Method


img_1.png

PartMix，通过混合不同模态的不见描述符（不同区域的特征，也就是人的不同部位）来合成增强样本，以提高基于零件的
VI-ReID 模型的性能。

我们合成了同一身份和不同身份之间的正样本和负样本，并通过对比学习对骨干模型进行正则化。
基于熵的挖掘策略

具体来说，给定可见光和红外图像，每种模态的特征图通过嵌入网络 E(·)
计算， 使得 f^t = E(x^t)。然后，部位检测器 D(·) 生成人体部位， 然后通过
sigmoid 函数 σ(·) 输出部位图概率，表示为 {mt(k)}^M_{k=1} =
σ(D(f^t))，其中 M是零件图的数量。 然后，零件描述符的公式如下： 
其中GAP(·)表示全局平均池化，⊙是逐元素乘法，[·]是连接操作。
他们最终连接全局描述符 gt ，使得 lt = GAP(ft) 和部分描述符 pt
以获得人物描述符 dt ，用于匹配从可见光和红外摄像机观察到的人，这样


img_4.png

g_t：全局特征， p_t: 局部特征， 进行拼接 ###
用于数据增强的部分混合
首先，直接应用全局图像混合方法会受到局部模糊和不自然的模式的影响，
为了客服这个问题，提出了一种针对基于部位的方法量身定制的数据
增强技术--PartMix， 它混合了，不同任务图像中提取的部位描述符。
具体来说，我们首先收集小批量的可见光和红外模式中的零件描述符，表示为描述符库。
，然后，我们通过跨模态 A(pv i
(u), pr j (h)) 和模内 A(pt i(u), pt j(h))
的部分混合操作依次混合部分描述符，如下所示：


img_5.png

其中 h、u 表示部分描述符 pt 的随机采样索引。
请注意，我们在上面的部分混合中排除了全局描述符
gt，因为它包含所有人体部分信息。
对比学习的样本生成


img_3.png

现有的基于图像混合的方法，通过线性插值图像和相应的标签来生成训练样本。
然而，这些方法仅用训练集中的身份组合来合成样本，
因此它们在测试集中的身份与训练集中的身份不同的 VI-ReID
任务上的泛化能力有限。 为了缓解这个问题，我们提出了一种样本生成策略，`
可以利用未见的人体部位组合（即未见的身份）来合成正样本和负样本。
在下面的部分中，我们将详细解释如何实现正bank B^{+,t}_i 和负bank
B^{−,t}_i 。 为了简单起见，仅描述可见样本作为示例 #### 阳性样本
我们的第一个见解是，具有相同身份的人的人类部分的组合必须是一致的。
为此，我们设计了正样本，将同一身份内的人物图像之间的相同部分信息混合在一起。
具体来说，我们使用（3）将具有相同身份的部分描述符混合在一起。可见模态的每个正样本表示为

Evaluation
Concusion
作者如何评估自己的方法，有没有问题或者可以借鉴的地方。 ## Notes
不自然模式(unnatural
pattern):图像混合相关术语。不自然模式可能是由于在图像混合、生成或者变换的过程中，
算法没有很好地保持图像局部区域的连贯性或一致性，导致生成的图像或混合样本看起来不符合常理或视觉上让人感到不真实。例如，某些图像区域的颜色、纹理、物体形状等特征显得突兀或异常，产生了不符合自然物体或场景的外观。
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/09/13/re-id/VI-ReID/MMM/" title="MMM"><img class="post-bg" src="/2024/09/13/re-id/VI-ReID/MMM/img_3.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MMM"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/13/re-id/VI-ReID/MMM/" title="MMM">MMM</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-09-13T08:35:09.519Z" title="Created 2024-09-13 16:35:09">2024-09-13</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/re-id/">re-id</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Unsupervised/">Unsupervised</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/VI-ReID/">VI-ReID</a></span></div><div class="content">用于无监督可见光-红外人员重新识别的多记忆匹配
出处：ECCV2024 ## Summery
写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段 ##
研究目标
无监督可见红外人员重新识别。USL-VI-ReID，利用数据本身特点生成为标签 ##
问题陈述 大多数现有方法并没有充分利用类内的细微差别，
因为它们只是利用代表身份的单个记忆来建立跨模态对应，从而导致嘈杂的跨模态对应。
## Method 为了解决这个问题，我们提出了 USL-VI-ReID
的多存储器匹配（MMM：Multi-Memory Matching）框架。
多存储器可以存储更广泛的身份独特特征。例如，内存1可以保留正面属性，内存2可以捕获背面属性。
我们通过子簇将单一身份的单一内存细分为多内存，并计算多内存的成本矩阵。 -
跨模态聚类（CMC）模块，通过将两个模态样本聚类在一起来生成伪标签。 -
我们设计了多记忆学习和匹配（MMLM）模块：关联跨模态聚类伪标签，确保优化明确关注个体视角的细微差别并建立可靠的跨模态对应。
- 我们设计了一种软簇级对齐（SCA：Soft Cluster-level Alignment
loss）损失来缩小模态差距，通过软簇级模内和模间对齐来缩小模态差距。
同时通过软多对多对齐策略减轻噪声伪标签的影响。  ### Notation Definition（符号定义） 假设我们有一个
USL-VI-ReID 数据集，表示为 D = {V, R}。 其中，V = {vi}Ni=1 表示 N
个样本的可见光图像，R = {ri}M i=1 表示 M 个样本的红外图像。
我们将它们的伪标签初始化为 Y t，其中 t ∈ {v, r}。令 Np 和 Mp 表示 ID 为
p 的可见光和红外样本的数量，其中 p ∈ {1, 2, ..., P t} 且 P t 是模态 t
的人员身份总数。这些图像各自的特征集表示为F v = {f v 1 , fv 2 ,…。 。 。
, fv N } 对于可见光样品，Fr = {fr 1 , fr 2,...,fr M }
对于红外样品。我们的目标是开发一个不使用任何标签的跨模态行人 ReID 模型。
### MMM
Evaluation


img.png

使用了ARI指数来表示聚类的相似性度量。ALL代表的是所有标签的相似性度量。
Concusion
作者如何评估自己的方法，有没有问题或者可以借鉴的地方。 ## Notes
ARI(Adjusted Rand Index):这是广泛认可的聚类评估指标。
ARI值越大，越能反映聚类结果与真实标签之间的重叠程度。
Adjusted Rand
Index（ARI，调整兰德指数）是一种用于衡量聚类结果与真实标签（或“真值”）之间相似度的指标。
它是 Rand
Index（兰德指数）的调整版本，旨在修正随机分配聚类结果时可能出现的偏差问题。
Rand Index (RI)
的基本思想是计算聚类结果和真实标签的配对样本之间的一致性，即查看所有可能的样本对，检查每对样本是否：
- 同时在相同的簇内（真值和预测结果一致）。 -
同时在不同的簇内（真值和预测结果一致）。
RI 的计算公式如下：


img_2.png

其中： - (a) 是两两样本同时在相同簇内的样本对数。 - (b)
是两两样本同时在不同簇内的样本对数。 - (C(n, 2))
是所有样本对的总数，即组合 (n )。
Adjusted Rand Index
Adjusted Rand Index 引入了对随机聚类结果的期望值的校正，消除了原始
Rand Index 在不同簇分配情况下可能产生的偏置。ARI 的取值范围在 -1 到 1
之间： - ARI = 1 表示聚类结果与真实标签完全一致。 - ARI = 0
表示聚类结果与随机分配的结果没有区别。 - ARI &lt; 0
表示聚类结果比随机分配的效果还差。
ARI 的公式如下：


img_1.png

其中： - () 是 Rand Index。 - ([]) 是 RI 的期望值，即随机聚类的 RI。
- (()) 是 RI 的最大值。
这种调整使得 ARI
不再依赖于数据集的大小、簇的数量或其他影响因素，能够更好地反映聚类结果的质量。
</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2024/09/12/tools/webstorm%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C/webstrom%E6%89%8B%E5%86%8C/" title="Untitled">Untitled</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-09-12T02:23:15.387Z" title="Created 2024-09-12 10:23:15">2024-09-12</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/tool/">tool</a></span></div><div class="content">文件重构
无法拖动或脱出标签--按Alt # hexo 常见命令








全称
缩写
作用




hexo generate
hexo g
生成静态文件


hexo server
hexo s
启动本地预览服务器


hexo clean
无
清理缓存和旧文件


hexo deploy
hexo d
部署静态网站


hexo new
hexo n
新建文章


hexo publish
无
发布草稿文章



</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/09/04/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/%E9%80%9A%E8%BF%87%E5%8F%8C%E6%A6%82%E7%8E%87%E5%BB%BA%E6%A8%A1%E5%AE%9E%E7%8E%B0%E7%A8%B3%E5%81%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%8F%8D%E6%AC%BA%E9%AA%97/" title="通过双概率建模实现稳健的人脸反欺骗"><img class="post-bg" src="/2024/09/04/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/%E9%80%9A%E8%BF%87%E5%8F%8C%E6%A6%82%E7%8E%87%E5%BB%BA%E6%A8%A1%E5%AE%9E%E7%8E%B0%E7%A8%B3%E5%81%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%8F%8D%E6%AC%BA%E9%AA%97/img_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="通过双概率建模实现稳健的人脸反欺骗"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/09/04/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/%E9%80%9A%E8%BF%87%E5%8F%8C%E6%A6%82%E7%8E%87%E5%BB%BA%E6%A8%A1%E5%AE%9E%E7%8E%B0%E7%A8%B3%E5%81%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%8F%8D%E6%AC%BA%E9%AA%97/" title="通过双概率建模实现稳健的人脸反欺骗">通过双概率建模实现稳健的人脸反欺骗</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-09-04T08:17:43.784Z" title="Created 2024-09-04 16:17:43">2024-09-04</time></span></div><div class="content">出处：arxiv2022 ## Summery
写完笔记之后最后填，概述文章的内容，以后查阅笔记的时候先看这一段 ##
研究目标 人脸反欺骗（FAS）， 也就是防止在人脸验证时的欺骗攻击
贡献：
我们首次全面研究了 FAS
数据集中的噪声问题。提出了称为双概率建模（DPM）的统一框架。
DPM由DPM-LQ和DPM-DQ组成，从标签和数据角度减轻噪声的负面影响。
我们进一步设计通用 DPM 来处理现实世界的 FAS 数据集，
而无需语义注释。它成功地处理了大规模样本中的噪声标签和退化数据。
大量实验表明，DPM 无需花哨的功能，就可以在多个标准 FAS
基准测试中取得最先进的结果。
问题陈述
由于其数据驱动的性质，现有的 FAS
方法对数据集中的噪声很敏感，这将阻碍学习过程。 然而，很少有工作在 FAS
中考虑噪声建模。


img.png

人脸反欺骗数据集中广泛存在三种噪声：标签模糊、标签噪声和数据噪声。
标签模糊是指很难为某些输入数据分配特定的语义标签。
我们将标签噪声称为错误注释的数据。
数据噪声是指质量极低的图像，例如严重模糊的脸部。 ## 方法
在这项工作中，我们试图通过以概率的方式从标签和数据的角度自动解决噪声问题来填补这一空白。
具体来说，我们提出了一个称为双概率建模（DPM）的统一框架，
具有两个专用模块：DPM-LQ（标签质量感知学习）和DPM-DQ（数据质量感知学习）。
这两个模块都是基于数据和标签应形成相干概率分布的假设而设计的。 DPMLQ
能够生成稳健的特征表示，而不会过度拟合噪声语义标签的分布。 DPMDQ
可以根据噪声数据的质量分布来校正其预测置信度，
从而消除推理过程中“错误拒绝”（False Reject）和“错误接受(False
Accept)”带来的数据噪声。
这两个模块都可以无缝、高效地融入现有的深度网络。 此外，我们提出了广义的
DPM 来解决实际使用中的噪声问题，而无需语义注释。

可以在单一概率模型下同时解决标签噪声和标签模糊问题，这对于FAS任务尤其有效。
每张图像的数据质量建模可以在训练过程中隐式结合，无需额外的模型，这当然可以使DPM既稳定又高效。
第三，DPM可以在已经经过QAM清理的测试集上进一步提高模型性能，
这表明QAM和DPM的功能并不完全重叠。



img_1.png

（PC、平板电脑或手机），很难用嵌入去映射是否为欺骗型标签分布，
由于低质量数据具有较大的(σD)2，因此可以使用(σD)2来校正低质量数据的预测置信度。


img_3.png

DPM-LQ


img_2.png

其中 N 为训练数据的个数，ωS ∈ RA×B 为 gS (·) 的参数， A
为语义信息的类别数，B 为 ωS 各行向量的维数，ωsi 为一行ωS
的向量，取决于语义标签 si。
不确定性建模


img_4.png

μi = hθ1 (xi), σ_L_i = h_{θ2} (μi) #### 语义信息分类损失 
然而，由于采样操作的性质不是差分的，因此将防止模型训练期间梯度流的反向传播。因此，对于来自高斯分布的随机样本
zi ，我们采用重新参数化技巧 [24] 从分布中“采样”zi 。 形式上，对于
μi，我们从正态分布中采样独立的随机噪声 ε
并将概率语义特征表示形式化如下


img_6.png

因此，我们将 zi 的随机部分转换为随机噪声 ε ，并使 μi 和 σL i 可训练。
具体来说，如果给定的训练样本标签不准确，DPM-LQ 不会强制 ωsi 的分布拟合
μi 的分布， 而是计算较大的方差来“放弃”该样本，从而减少其对 ωsi
分布的影响。
换句话说，这个额外的维度允许模型更多地关注具有干净标签的数据，而不是具有不准确标签的样本，
从而实现更好的类可分离性和更好的泛化。 ### DPM-DQ #### 特征分布于建模
为了校正噪声数据的预测置信度，DPM-DQ 在潜在空间中制定了两个高斯分布。
给定输入图像 xi 及其 Live/Spoof 地面实况 ci，ωci
可以视为其标准特征表示，即高斯分布的均值，如下所示：


img_7.png

其中 μi 可以被视为该分布中的样本或观察到的特征表示。
真实/虚假类别分类损失
高斯分布是通过最大化以下对数似然来制定的:


img_8.png

其中 (σD i )2 = hθ3 (xi)，θ3 表示模型参数 w.r.t (σD i
)2。与等式不同。 也就是以下损失函数最小化


img_9.png

我们利用 exp (− (ω−μ)2/ 2(σD)2 ) 来替换 softmax 中的 exp
(ωμ)。(正则化操作)
(σD)2 可用于校正其预测置信度。
为什么噪声数据的方差较大
方差是根据特征表示的差异进行估计的。
较大的差异会导致较大的方差，而对于潜在空间中相似的样本（即使是难处理的样本），方差也不会显著增大。
Evaluation


img_10.png

（a)当标签噪声的比例稍微变大（小于50%）时，DPM-LQ仍然可以提高分类性能。
然而，随着标签噪声变得极其严重，DPM-LQ 几乎无法工作。 (b)
当数据噪声比例较低时，DPM-DQ 可以略微提高模型性能。
此外，当数据噪声比例处于中等水平（20%、30%）时，DPM-DQ可以明显提高DPM的性能。
然而，当数据噪声变得极其严重时，DPM-DQ几乎不起作用。 (c) 仅在已清理了前
5% 的相对低质量数据的测试集上进行测试，没有 DPM
的模型可以达到与在整个测试集上测试的带有 DPM
的模型相当的性能。此外，DPM还可以进一步提高“更干净”的测试数据的性能。 ##
Concusion 作者如何评估自己的方法，有没有问题或者可以借鉴的地方。 ##
Notes 隐式结合： 隐式结合（Implicit
Incorporation）是指在模型训练过程中，
某些因素或信息无需通过显式的独立模型或显式设计的特征，
而是通过已有的模型结构、训练过程或参数优化方法自然地整合进来。
这种方式可以让模型自动从数据中捕捉、学习和应用这些信息，而不需要明确地将其分离处理。
</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2024/08/25/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/PUM/" title="Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation"><img class="post-bg" src="/2024/08/25/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/PUM/img_1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/08/25/%E6%A6%82%E7%8E%87%E5%B5%8C%E5%85%A5/PUM/" title="Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation">Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-08-25T07:29:34.131Z" title="Created 2024-08-25 15:29:34">2024-08-25</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Probabilistic/">Probabilistic</a></span></div><div class="content">2021 cvpr ## Summery
为了生成“准确”的场景图，几乎所有现有方法都以确定性方式预测成对关系。
然而，我们认为视觉关系在语义上通常是模糊的。
具体来说，受语言学知识的启发，我们将歧义分为三种类型：同义歧义、下位歧义和多视图歧义。
这种模糊性自然会导致隐式多标签的问题，从而激发了对多样化预测的需求。
在这项工作中，我们提出了一种新颖的即插即用概率不确定性建模（PUM）模块。
它将每个联合区域建模为高斯分布，其方差衡量相应视觉内容的不确定性。
与传统的确定性方法相比，这种不确定性建模带来了特征表示的随机性，这自然可以实现多样化的预测。
作为副产品，PUM
还成功地涵盖了更细粒度的关系，从而缓解了对频繁关系的偏见问题。
对大规模视觉基因组基准的大量实验表明，将 PUM 与新提出的 ResCAGCN
相结合可以实现最先进的性能，特别是在平均召回率指标下。 此外，我们通过将
PUM 插入一些现有模型来展示 PUM
的普遍有效性，并对其生成多样化但合理的视觉关系的能力进行深入分析。 -
我们识别了视觉关系的语义模糊性，并提出了一种新颖的即插即用概率不确定性建模（PUM）模块，该模块利用概率分布来表示每个联合区域而不是确定性特征向量。
- 将 PUMP 与 ResCAGCN
相结合，我们在现有评估指标（尤其是平均召回率）下在大规模视觉基因组基准测试中实现了最先进的性能。
- 广泛的评估表明，当插入现有的 SGG 模型时，PUM
在减轻对频繁类别的偏差方面具有优越性，这反映在平均召回率的提高上。 -
据我们所知，我们是第一个探索 SGG
多样化预测的人。我们进行定性和定量实验，以证明所提出的 PUM
模块可以生成多样化但合理的关系。 ## Research Objective 场景图生成。
作为中间任务来弥合上游对象检测和下游高级视觉理解任务之间的差距，例如图像字幕和视觉问答。
Problem Statement


img.png

Visual Genome dataset数据集中语义歧义的示例。
前两列显示了相似视觉场景的两个合理谓词之间的比较，最右边的列说明了语义空间中的相应现象。
- 携带和持有的定义有重叠，并且可以互换来描述人与雨伞之间的关系。
同义歧义 - 尽管语义特异性不同，“on”和“laying
on”都可以合理地描述猫在长凳上的场景。 下位歧义 -
不同的人类注释者侧重于不同的观点，即使用（动作）与前面（空间）来描述工人和笔记本电脑。多视图歧义
## Method 
现有的SGG框架通常包括以下步骤： - 图 2 (a)(b)(c)
描述的应该是这些步骤的流程图： - (a) 目标检测模块（使用
Faster R-CNN 生成边界框和类别预测）。 - (b)
根据候选边界框和类别标签，对对象之间的关系进行推理。 -
(c) 最终通过对象及其关系，生成整张图像的场景图。
传统上，给定图像 I，场景图 P (G|I) 的概率分布被分解为三个因素 [35,
4]：
P (G|I) = P (B|I)P (O|B, I)P (R|O, B, I)
P(B|I) - 边界框预测模型。 faster-RCNN 生成可能目标物品的边界框 P(B∣I)
表示给定图像I 的条件下，生成边界框B
的概率。换句话说，它是在图像中找到可能包含目标的区域。建模该概率分布，
P(O|B, I) - 目标类别预测模型：(P(O|B, I)) 表示在给定边界框 (B) 和图像
(I) 的条件下，预测目标对象 (O)
属于某一类的概率。这是分类阶段，确定每个框内物体的类别。
P(R|O, B, I) - 关系推理模型：
关系推理是第三个步骤，基于前两步的目标检测结果，模型推断不同目标对象之间的关系。概率分布
(P(R|O, B, I)) 表示在给定目标对象 (O)（以及对应的边界框 (B) 和图像
(I)）的条件下，预测对象间关系 (R)
的概率。例如，判断两个对象之间的关系是“骑乘”还是“站在上面”等。
对象模型
介绍了baseline与baseline的区别。
残差交叉注意力图卷积网络（ResCAGCN），ResCAGCN
的核心是交叉注意模块（CA），旨在捕获对象特征和成对联合区域特征之间的语义相关性。


img_3.png

⊙ 和 ⊕ 表示逐元素乘积和总和，σ 是用于标准化注意力分数的 sigmoid
函数。
给定两个对象特征 xi 和 xj 及其联合区域特征 uij，
为了对上下文信息进行建模，ResCAGCN 利用交叉注意力模块来计算上下文系数
cij，其公式为：
 
残差相加。Ni 表示第 i 个节点的邻域，LN
表示层归一化。然后将精炼后的对象特征 xi
输入到分类器中以预测对象标签。
概率不确定性建模PUM
传统上，两个提案的候选框被表示为空间中的单个点，即点嵌入[20]。
然而，正如[26]所观察到的，这种点估计并不能自然地表达输入引起的不确定性。在视觉关系的情况下，这可能是由不明确的注释引起的，例如“拿着”和“看着”都可以用来描述包含一个男人和一部手机的场景。
如图2（d）所示，为了捕捉视觉关系的内在不确定性，我们建议将每个联合区域的特征分布显式建模为高斯分布。也就是说，我们将每个联合区域表示为随机嵌入，而不是传统的点嵌入。从随机的角度来看，每个联合区域的最终表示不再是确定性向量，而是从高斯分布中随机抽取。因此，我们可以为同一对象对生成不同的谓词，从而导致场景图生成的多样性。
随机表示 Stochastic
Representation
对于每个对象对，遵循 ResCAGCN，我们首先融合它们的上下文对象特征 xi 和
xj （如第 3.1 节所述） 以及它们的视觉联合区域特征 uij
以获得关系特征：


img_6.png

⋄ 定义的融合函数 
基于每个融合关系特征，我们将潜在空间中的相关表示 zij
定义为高斯分布，


img_9.png

其中 μij 和 σi2j 分别指均值向量和对角协方差矩阵。它们的公式为：


img_10.png

在测试时，我们对多个 zijs 进行采样，将它们分别输入关系分类器 φr
并计算平均后验概率分布：


img_11.png

其中 z(k) ij ∼ N (μij, σi2j)，K
是从高斯分布中抽取的样本数。然后我们简单地将 Pij 的 argmax
作为预测关系标签
不确定性损失
μij 可以看作是联合框的原始确定性表示，而随机变量 zij
则作为随机表示样本。在这里，我们考虑这两种表示并将它们分别输入到 φr
中。然后，我们用交叉熵损失训练关系模型，


img_12.png

其中 λ 是确定性预测和随机预测之间权衡的权重，CE
表示交叉熵损失。请注意，为了清楚起见，我们省略了下标
ij。在实践中，我们通过蒙特卡洛采样从 z(k) ∼ p(z|e) 近似期望项：


img_13.png

其中 N
是从高斯中抽取的样本数。显然，传统的确定性训练可以被视为方程的一个特例。
11 其中 λ 设置为 0。
受[34]的启发，随着训练的进行，方差 σ2 总是随着 Lce
单独减小，并将我们的随机表示恢复为确定性模型。这个问题可以通过以下正则化项来缓解：


其中 γ=200 是限制不确定性水平的余量，h(N (μ, σ2))
是多元高斯分布的微分熵，实际上仅与 σ 有关：
为了让方差乘积=200，防止方差为0， 也就是让高斯更加的平滑
概率损失: 
重参技巧
重新参数化技巧。直接从 N (μ, σ2) 中采样 z
将防止梯度传播回前面的层。因此，我们使用重新参数化技巧[11]来绕过这个问题。具体来说，我们首先从标准高斯中采样随机噪声
ε 并生成 z 作为等效采样表示，z = μ + εσ, ε ∼ N (0, I)。
Evaluation
实施细节。继之前的工作[35,4,24]之后，我们采用相同的Faster-RCNN[21]来检测对象边界框并提取RoI特征。
对于 PUM 中的超参数，我们将 K 设置为 8，N 设置为 8，λ 设置为 0.1，γ
设置为 200。我们通过 Adam 优化器优化所提出的模型，批量大小为 8，动量为
0.9 和 0.999。我们的方法是由 Pytorch 和 MindSpore
实现的。直观上，我们的不确定性建模会导致性能差异。
Concusion
在这项工作中，我们考虑了视觉关系的语义歧义，可以分为同义歧义、下义歧义和多视图歧义。
为了解决由歧义引起的隐式多标签问题，我们提出了一种新颖的即插即用模块，称为
PUM。 尽管我们的目标是多样化的预测，但由于 PUM 的副产品，当将其与
ResCAGCN 结合时，我们在现有评估指标下实现了最先进的性能。
此外，我们展示了 PUM
的普遍有效性，并探索了它在定性和定量方面产生多样化但合理的关系的能力。
未来可能的方向是将这种不确定性模型应用于也强调多样性的下游任务中，例如多样化的视觉字幕
[5,22,29]。 ## Notes 视觉问答就是输入图像，输入文本问题，生成回答。
对频繁关系的偏见问题:是指在场景图生成（SGG）或其他关系检测任务中，模型倾向于更准确地识别和预测在训练数据中出现频率较高的关系，而忽视或低估那些不常见或罕见的关系。
σ 是用于标准化注意力分数的 sigmoid 函数。
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2024/08/12/re-id/Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty/" title="Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty"><img class="post-bg" src="/2024/08/12/re-id/Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty/img.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty"></a></div><div class="recent-post-info"><a class="article-title" href="/2024/08/12/re-id/Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty/" title="Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty">Robust_Person_Re-identification_by_Modelling_Feature_Uncertainty</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2024-08-12T13:46:37.653Z" title="Created 2024-08-12 21:46:37">2024-08-12</time></span><span class="article-meta tags"><span class="article-meta-separator">|</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/re-id/">re-id</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Uncertainty/">Uncertainty</a><span class="article-meta-link">•</span><i class="fas fa-tag"></i><a class="article-meta__tags" href="/tags/Probabilistic/">Probabilistic</a></span></div><div class="content">2019 ICCV ## Summery 主要贡献： - 首次确定了学习 ReID
模型对标签噪声和外围样本具有鲁棒性的问题， 并提供了统一的解决方案。 -
提出了一种称为 DistributionNet 的新型深度 ReID 模型，
该模型将每个学习的深度特征独特地建模为分布，
以考虑特征不确定性并减轻噪声样本的影响。 - 成员变化模块（MVM） -
MVM定义了一个随机变量p来描述群体内成员变化的概率分布。 -
群体成员出现在不同摄像头下时，他们的状态通常不会发生太大变化（例如行为、位置等会保持一致）。
- 成员消失后，剩下的成员更不容易发生变化。 -
考虑到实际输入的图像不一定包含群体的所有成员，MVM
会根据图像中的实际情况动态调整𝑝使模型适应当前的图像内容。 -
布局变化模块（LVM）关注每个成员的布局变化，由于很难穷尽所有的空间位置，LVM
将一定数量的成员下所有可能的空间位置归一化为同一个布局特征。为此，设计了可学习的存储体M来描述布局特征。
- 二阶transformer框架（SOT）由成员内模块和成员间模块组成。
具体来说，成员内模块提取每个成员的一阶token，
然后成员间模块通过上述一阶token学习到一个二阶token作为群体特征 -
广泛的比较评估表明，所提出的模型在四个基准上优于现有模型， 包括
Market-1501、DukeMTMCReID、CUHK01和 CUHK03。
我们表明，考虑到大量标签噪声或在更具挑战性的开放世界 ReID
设置下，所提出的模型特别有效。
研究目标
学习对噪声训练数据具有鲁棒性的深度行人重新识别（ReID）模型  ## 问题陈述 -
研究旨在解决在训练深度行人重识别（ReID）模型时，如何应对噪声训练数据的问题。具体而言，研究聚焦于两种常见的噪声类型：
1.
标签噪声：由人工标注错误引起，即训练图像被分配了错误的标签。
2.
数据异常值：由行人检测器错误或遮挡引起，导致图像本身不具有代表性或被破坏。
- 这些噪声会显著降低 ReID 模型的性能，但在现有研究中尚未得到充分关注。
## 方法 将 fθ(X(i)) 建模为由神经网络产生的均值向量
μ(i) 和协方差矩阵 Σ(i) 组成。


img.png



img_1.png



img_2.png

xxw
对完整协方差矩阵进行建模的成本非常高，因此我们将其限制为对角矩阵。因此，f_θ_Σ
产生与 fθ 大小相同的向量
传统的分类损失，先提取特征，再经过一个分类器，最后使用交叉熵损失，如下所示


img_3.png

对于DistributionNet，因此，我们向分类器提供两种输入： ·均值向量
μ，它作为 fθ(X) 的直接替代； ·从由 (μ, Σ) 参数化的高斯分布中抽取的 N
个随机样本。 λ 是采样特征向量的权重，设置为 0.1。
如果没有采样部分，则退化为传统的交叉熵损失


img_4.png

特征不确定损失
为了防止方差的平凡解减小到零，我们添加了特征不确定性损失，以鼓励模型保持整个训练样本的不确定性水平。
为此，我们首先使用熵来测量单个训练样本在给定方差 Σ
的情况下的不确定性水平。任意多元高斯分布的熵为：


img_5.png

大的方差导致大的熵。回想一下，我们学习到的特征分布是对角多元正态分布。所以上面的等式对于第
i 个输入图像等价于


img_6.png

其中diag(·)表示输入矩阵的对角向量，m是特征总维度，k对每个维度进行索引。然后特征不确定性损失被公式化为：


img_7.png

其中 n 是小批量大小，i 对批次中的图像进行索引，γ
是总不确定性界限的余量。 显然，使用
L_{fu}，模型更愿意保持训练样本的总不确定性方差。
由于分类损失导致干净样本的方差总是较小，因此噪声样本的方差预计会较大，以保持所有样本的总不确定性。
重新参数化技巧当使用随机样本 z 来训练 g_φ 时，会出现一个问题：
由于随机样本的性质，误差不会传播回前面的层。
为了使这些层也从随机样本中受益，我们在采样期间使用了重新参数化技巧。
具体来说，我们不是直接从 N (μ, Σ) 中抽取样本，
而是首先从均值为零、单位协方差为零的标准高斯中抽取样本 ε，即 ε ∼ N (0,
I)， 然后得到样本通过计算 μ +
εΣ。通过这样做，我们将样本中的随机部分和可训练部分分开，因此梯度可以通过可训练部分传递。
由于损失，DistributionNet 表现出两种行为：
（1）它为噪声样本（带有错误标签或离群样本）提供了大的方差，为干净的内点提供了小方差。
(2) 方差较大的训练样本对学习特征嵌入空间的贡献较小。
通过将两者结合起来，模型实际上主要关注干净的内点，以学习更好的 ReID
嵌入空间。
为什么方差较大的样本对模型训练的贡献较小？
原因很直观——如果图像嵌入有很大的方差，那么在采样时，结果 z
将远离其原始点（平均向量 μ），但具有相同的类标签。 因此，当将几个不同的
z(1)、z(2)、...、z(N) 和 μ 输入到分类器时，它们的梯度很可能会相互抵消。
另一方面，当样本方差较小时，所有z(j)都会接近μ；将它们输入分类器会产生一致的梯度，从而增强样本的重要性。
因此，方差/不确定性为 DistributionNet
提供了一种机制，可以对不同的训练样本给予更多/更少的重要性。
由于噪声样本被赋予较大的方差，因此它们对模型训练的贡献减少，从而产生更好的特征嵌入空间（示例见图
4）。 ## Evaluation 噪声的引入分为两类： - 随机噪声
是完全不考虑样本特征的，只是随机改变标签，因此是一种非结构化的噪声。（id
switch） - 模式化噪声
用resnet50抽取特征相似的人物进行交换，模拟了在现实中可能会因视觉或特征相似性导致的误标注。
分别考虑10%、20%、50%，对于每个噪声百分比，由于样本选择和标签分配的随机性，进行
5 次运行。最终报告的结果是 5 次运行的平均值。
    
开放世界的ReID设置
在开放世界的ReID设置中，使用少量身份来形成目标，并且测试图库集仅包含这些目标身份的图像。
对于每个数据集，目标的两个图像形成图库列表。
训练集中剩余的目标图像的一半和所有非目标图像构成训练集。
测试集中的另一半目标图像和非目标图像用作探针列表。
此设置的关键挑战是探针组包含许多需要拒绝的冒名顶替者。
我们使用真实目标率（TTR）和错误目标率（FTR）作为基于集合和基于个体的验证任务的评估指标
 ## Concusion
在这项工作中，我们首次解决了学习深度 ReID
模型时的噪声标签和异常样本问题。
提出了一种处理这两种类型的噪声样本的统一解决方案。关键思想是通过将每个特征建模为分布来显式地建模特征不确定性。
由此产生的 DistributionNet
能够通过向噪声样本分配较大的方差来减轻噪声样本的负面影响。
进行了大量的实验来验证 DistributionNet
的有效性。事实证明，它在各种环境下都优于许多最先进的竞争对手。
Notes
</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><a class="page-number" href="/page/5/#content-inner">5</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/nav.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Mona</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">42</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">37</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/mona12138"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/mona12138" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="https://github.com/mona12138" target="_blank" title="Github"><i class="fab fa-gitHub" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:manyuwei@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">如果对图像处理有兴趣可以邮件联系我~</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/04/11/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/" title="离散数学">离散数学</a><time datetime="2025-04-11T12:34:02.000Z" title="Created 2025-04-11 20:34:02">2025-04-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/22/TI-ReID/" title="TI-ReID">TI-ReID</a><time datetime="2025-01-22T09:08:07.000Z" title="Created 2025-01-22 17:08:07">2025-01-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/01/13/lidar-based-ReID/" title="lidar-based_ReID">lidar-based_ReID</a><time datetime="2025-01-13T13:01:11.000Z" title="Created 2025-01-13 21:01:11">2025-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/30/tools/%E5%A4%AE%E8%A7%86%E7%BD%91%E8%A7%86%E9%A2%91%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD/" title="央视网视频批量下载方法">央视网视频批量下载方法</a><time datetime="2024-12-30T07:09:23.386Z" title="Created 2024-12-30 15:09:23">2024-12-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/12/16/Sigma-Siamese-Mamba-Network-for-Multi-Modal-Semantic-Segmentation/" title="Sigma : Siamese Mamba Network for Multi-Modal Semantic Segmentation">Sigma : Siamese Mamba Network for Multi-Modal Semantic Segmentation</a><time datetime="2024-12-16T02:45:51.000Z" title="Created 2024-12-16 10:45:51">2024-12-16</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Re-ID/"><span class="card-category-list-name">Re-ID</span><span class="card-category-list-count">7</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Re-ID-VI-ReID/"><span class="card-category-list-name">Re-ID - VI-ReID</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Re-ID-Person/"><span class="card-category-list-name">Re-ID -Person</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Re-ID-VI-ReID/"><span class="card-category-list-name">Re-ID -VI-ReID</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Re-id-object-Re-id/"><span class="card-category-list-name">Re-id - object Re-id</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/person-retrieval/"><span class="card-category-list-name">person retrieval</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/tool/"><span class="card-category-list-name">tool</span><span class="card-category-list-count">2</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Multi-Modal/" style="font-size: 1.15em; color: rgb(32, 139, 159)">Multi-Modal</a><a href="/tags/open-sourse/" style="font-size: 1.39em; color: rgb(177, 86, 129)">open-sourse</a><a href="/tags/Re-ID/" style="font-size: 1.45em; color: rgb(110, 98, 39)">Re-ID</a><a href="/tags/LiDAR/" style="font-size: 1.15em; color: rgb(77, 113, 156)">LiDAR</a><a href="/tags/Text-Image/" style="font-size: 1.15em; color: rgb(186, 102, 187)">Text-Image</a><a href="/tags/Noisy-Correspondence/" style="font-size: 1.15em; color: rgb(162, 17, 93)">Noisy-Correspondence</a><a href="/tags/EECS/" style="font-size: 1.15em; color: rgb(118, 184, 155)">EECS</a><a href="/tags/re-rank/" style="font-size: 1.15em; color: rgb(123, 61, 114)">re-rank</a><a href="/tags/re-id/" style="font-size: 1.33em; color: rgb(67, 24, 129)">re-id</a><a href="/tags/English/" style="font-size: 1.27em; color: rgb(199, 130, 124)">English</a><a href="/tags/tools/" style="font-size: 1.15em; color: rgb(93, 13, 93)">tools</a><a href="/tags/Part/" style="font-size: 1.15em; color: rgb(65, 107, 135)">Part</a><a href="/tags/part/" style="font-size: 1.15em; color: rgb(194, 87, 136)">part</a><a href="/tags/open-sourse/" style="font-size: 1.21em; color: rgb(164, 46, 161)">open sourse</a><a href="/tags/Unsupervised/" style="font-size: 1.33em; color: rgb(163, 106, 181)">Unsupervised</a><a href="/tags/open-source/" style="font-size: 1.15em; color: rgb(25, 149, 89)">open-source</a><a href="/tags/cross-modality/" style="font-size: 1.15em; color: rgb(97, 26, 12)">cross-modality</a><a href="/tags/object/" style="font-size: 1.15em; color: rgb(56, 130, 26)">object</a><a href="/tags/Noisy-labels/" style="font-size: 1.15em; color: rgb(87, 117, 53)">Noisy labels</a><a href="/tags/Noisy-correspondence/" style="font-size: 1.15em; color: rgb(146, 82, 59)">Noisy correspondence</a><a href="/tags/Uncertainty/" style="font-size: 1.21em; color: rgb(186, 85, 176)">Uncertainty</a><a href="/tags/Probabilistic/" style="font-size: 1.21em; color: rgb(141, 52, 191)">Probabilistic</a><a href="/tags/Group-re-id/" style="font-size: 1.15em; color: rgb(40, 68, 181)">Group re-id</a><a href="/tags/GPT/" style="font-size: 1.21em; color: rgb(113, 183, 101)">GPT</a><a href="/tags/%E6%9C%89%E8%B6%A3/" style="font-size: 1.21em; color: rgb(85, 17, 150)">有趣</a><a href="/tags/practice/" style="font-size: 1.15em; color: rgb(78, 75, 5)">practice</a><a href="/tags/tool/" style="font-size: 1.21em; color: rgb(162, 60, 2)">tool</a><a href="/tags/VI-ReID/" style="font-size: 1.39em; color: rgb(54, 128, 138)">VI-ReID</a><a href="/tags/Noisy-Labels/" style="font-size: 1.15em; color: rgb(144, 169, 191)">Noisy Labels</a><a href="/tags/Neighbor-Relation-Learning/" style="font-size: 1.15em; color: rgb(36, 175, 31)">Neighbor Relation Learning</a><a href="/tags/Optimal-Transport/" style="font-size: 1.15em; color: rgb(76, 135, 165)">Optimal Transport</a><a href="/tags/Graph-Matching/" style="font-size: 1.15em; color: rgb(39, 188, 154)">Graph Matching</a><a href="/tags/Alter-learning/" style="font-size: 1.15em; color: rgb(2, 65, 72)">Alter learning</a><a href="/tags/open-source/" style="font-size: 1.15em; color: rgb(144, 138, 36)">open source</a><a href="/tags/%E5%88%86%E5%9D%97/" style="font-size: 1.15em; color: rgb(140, 166, 22)">分块</a><a href="/tags/Auxiliary-modality/" style="font-size: 1.15em; color: rgb(159, 42, 36)">Auxiliary modality</a><a href="/tags/VI-re-id/" style="font-size: 1.15em; color: rgb(90, 19, 69)">VI re-id</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span><a class="card-more-btn" href="/archives/" title="View More">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/04/"><span class="card-archive-list-date">April 2025</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">January 2025</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">December 2024</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/11/"><span class="card-archive-list-date">November 2024</span><span class="card-archive-list-count">7</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">October 2024</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/09/"><span class="card-archive-list-date">September 2024</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">August 2024</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">July 2024</span><span class="card-archive-list-count">9</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">42</div></div><div class="webinfo-item"><div class="item-name">Runtime :</div><div class="item-count" id="runtimeshow" data-publishDate="2025-04-28T07:35:58.428Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Update :</div><div class="item-count" id="last-push-date" data-lastPushDate="2025-04-28T07:35:58.428Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Mona</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="Toggle Between Traditional Chinese And Simplified Chinese">繁</button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="chat-btn" type="button" title="Chat"><i class="fas fa-sms"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: (str) => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: (subtitleType) => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        getScript('https://cdn.jsdelivr.net/npm/typed.js@2.1.0/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["靡不有初，鲜克有终","Never put off till tomorrow what you can do today","许多人终其一生都想从别人身上找寻爱，以为爱是自然界的第二个太阳。","却忘了自己才是那道照耀全世界的光。"])
  } else {
    document.getElementById("subtitle").textContent = "靡不有初，鲜克有终"
  }
}
typedJSFn.run(subtitleType)</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid@10.8.0/dist/mermaid.min.js').then(runMermaid)
  }

  btf.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><script src="/js/spark_lite_post_ai.js"></script><div class="aplayer no-destroy" data-id="12513757136" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true"> </div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>